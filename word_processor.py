# import nltk
from nltk.tokenize import word_tokenize

f_arise = open('arise.txt')
arise_tokenized_two = word_tokenize(f_arise.read())
